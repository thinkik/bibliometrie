<div class="module-role-panel">
  <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
  <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
    <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
    <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
    <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
  </div>
  <div class="module-role-hints">
    <div class="role-hint" data-role="Bibliothek" hidden>
      Hinweis: Prüft, welche Datenbanken eure Nutzerinnen und Nutzer bereits kennen.
    </div>
    <div class="role-hint" data-role="Bibliothek" hidden>
      Hinweis: Bereitet eine kurze Übersicht zu Abdeckungsgrenzen der wichtigsten Quellen vor.
    </div>
    <div class="role-hint" data-role="Research Office" hidden>
      Hinweis: Legt fest, welche Quellen im Reporting priorisiert werden und warum.
    </div>
    <div class="role-hint" data-role="Research Office" hidden>
      Hinweis: Klärt, wie ihr Datenlücken transparent in Berichten kennzeichnet.
    </div>
    <div class="role-hint" data-role="Forschende" hidden>
      Hinweis: Notiert, welche Publikationswege in eurem Feld fehlen könnten.
    </div>
    <div class="role-hint" data-role="Forschende" hidden>
      Hinweis: Überlegt, wie ihr eure eigenen Publikationslisten aktuell halten wollt.
    </div>
  </div>
</div>
<script src="../role-toggle.js" defer></script>

# Modul 2: Datenquellen und Datenqualität

## Lernziele
- Bibliometrische Datenquellen vergleichen
- Datenqualität prüfen und dokumentieren
- Auswirkungen von Abdeckung und Bias erklären

## Kurz erklärt
Bibliometrische Analysen hängen stark von der Datenquelle ab. Dieses Modul vergleicht Web of Science, Scopus, Dimensions, Crossref und offene Repositorien hinsichtlich Abdeckung und Metadaten. Sie lernen, welche Publikationstypen und Fächer wie gut vertreten sind und wie Sprach- oder Regionseffekte entstehen. Wir betrachten typische Qualitätsprobleme wie Dubletten, Autorennamensvarianten, fehlende Referenzen und inkonsistente Affiliations. Außerdem sehen Sie, wie Lizenzbedingungen, APIs und Exportformate die Analyse beeinflussen. Sie prüfen zudem, wie sich Dublettenbereinigung und Feldzuordnung auf Kennzahlen auswirken. Darauf aufbauend üben Sie, eine Datenbasis zu dokumentieren und zu begründen, warum sie für eine Fragestellung geeignet ist. Das schafft Transparenz und verhindert Fehlinterpretationen, die allein aus Datenlücken resultieren.

## Vertiefung
- Zentrale Begriffe und Definitionen sammeln und mit Beispielen illustrieren.
- Begrenzen, welche Aussagen mit den gewählten Daten tatsächlich möglich sind.
- Ein kurzes Reflexionsprotokoll zu Annahmen, Datenlücken und Bias erstellen.

## Typische Fehlinterpretationen
- Indikatoren als direkte Qualitätsurteile verwenden.
- Unterschiedliche Fächer oder Zeitfenster ohne Normalisierung vergleichen.
- Datenlücken oder Dubletten ignorieren.

## Mini-Übungen (Level 1–3)
- **Level 1:** Ein zentrales Konzept in zwei Sätzen definieren.
- **Level 2:** Ein kleines Datenset skizzieren und passende Indikatoren vorschlagen.
- **Level 3:** Eine kurze Interpretation schreiben und mögliche Bias benennen.

## Praxis-Workflow
1. Fragestellung präzisieren und Zielgruppe definieren.
2. Datenquelle auswählen und dokumentieren.
3. Indikatoren berechnen und validieren.
4. Ergebnisse visualisieren und interpretieren.
5. Bericht mit Limitationen veröffentlichen.

## Responsible-Metrics-Box
- Verwenden Sie mehrere Indikatoren und erläutern Sie deren Grenzen.
- Kombinieren Sie quantitative Werte mit qualitativen Einschätzungen.

## Quellen & weiterführende Links
- https://www.dora.org/
- https://www.leidenmanifesto.org/
- https://www.crossref.org/
