<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Einführung Bibliometrie – Lehrgang</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="brand">Einführung Bibliometrie</div>
      <nav class="site-nav" aria-label="Hauptnavigation">
        <a href="index.html">Start</a>
        <a class="active" href="lehrgang.html">Lehrgang</a>
        <a href="uebungen.html">Übungen</a>
        <a href="fallstudien.html">Fallstudien</a>
        <a href="tools-datenquellen.html">Tools &amp; Datenquellen</a>
        <a href="responsible-metrics.html">Responsible Metrics</a>
        <a href="glossar.html">Glossar</a>
        <a href="downloads-vorlagen.html">Downloads &amp; Vorlagen</a>
        <a href="faq.html">FAQ</a>
      </nav>
    </header>
    <main class="content">
      <h1>Lehrgang</h1>
      <p>
        Hier findest du die Module 1–3 des Lehrgangs. Nutze die Hinweise für deine Rolle, um die
        wichtigsten Punkte gezielt zu vertiefen.
      </p>

      <section class="module-section" id="modul-1">
        <h2>Modul 1: Einführung in die Bibliometrie</h2>
        <div class="module-role-panel">
          <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
          <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
            <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
            <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
            <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
          </div>
          <div class="module-role-hints">
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Klärt mit dem Team, welche bibliometrischen Basisbegriffe in Schulungen konsistent
              verwendet werden sollen.
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Notiert typische Nutzerfragen, um spätere Beratungsangebote daran auszurichten.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Haltet fest, welche Kennzahlen für interne Reports wirklich benötigt werden.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Prüft früh, welche Datenquellen für zentrale Entscheidungen akzeptiert sind.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Überlegt, welche Indikatoren eure Arbeit sinnvoll ergänzen, ohne sie zu reduzieren.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Sammelt Beispiele, wo Zitationszahlen missverstanden wurden, um gegenzusteuern.
            </div>
          </div>
        </div>

        <h3>Lernziele</h3>
        <ul>
          <li>Grundbegriffe der Bibliometrie erklären</li>
          <li>Zitationsdaten als Indikatoren einordnen</li>
          <li>Einsatzbereiche und Grenzen benennen</li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Bibliometrie untersucht wissenschaftliche Kommunikation anhand von Publikations- und
          Zitationsdaten. In diesem Modul lernen Sie, warum Zitationen als Hinweis auf Rezeption dienen,
          aber nicht mit Qualität gleichgesetzt werden dürfen. Wir betrachten typische Fragestellungen wie
          Forschungsleistung messen, Themenfelder beobachten oder Kooperationen sichtbar machen. Zugleich
          klären wir Begriffe wie Publikationstypen, Zitationsfenster, Datenbanken und die Rolle von
          Referenzen. Wir unterscheiden deskriptive Analysen von evaluativen Anwendungen und besprechen,
          welche Entscheidungen auf welcher Evidenz beruhen sollten. Ein besonderer Fokus liegt auf
          verantwortungsvollem Umgang mit Kennzahlen: Indikatoren sind Werkzeuge zur Orientierung, keine
          Urteile. Am Ende können Sie die Rolle der Bibliometrie im Forschungsmanagement einordnen und
          erkennen, welche Datenbasis für valide Aussagen nötig ist.
        </p>

        <h3>Vertiefung</h3>
        <ul>
          <li>Zentrale Begriffe und Definitionen sammeln und mit Beispielen illustrieren.</li>
          <li>Begrenzen, welche Aussagen mit den gewählten Daten tatsächlich möglich sind.</li>
          <li>Ein kurzes Reflexionsprotokoll zu Annahmen, Datenlücken und Bias erstellen.</li>
        </ul>

        <h3>Typische Fehlinterpretationen</h3>
        <ul>
          <li>Indikatoren als direkte Qualitätsurteile verwenden.</li>
          <li>Unterschiedliche Fächer oder Zeitfenster ohne Normalisierung vergleichen.</li>
          <li>Datenlücken oder Dubletten ignorieren.</li>
        </ul>

        <h3>Mini-Übungen (Level 1–3)</h3>
        <ul>
          <li><strong>Level 1:</strong> Ein zentrales Konzept in zwei Sätzen definieren.</li>
          <li><strong>Level 2:</strong> Ein kleines Datenset skizzieren und passende Indikatoren vorschlagen.</li>
          <li><strong>Level 3:</strong> Eine kurze Interpretation schreiben und mögliche Bias benennen.</li>
        </ul>

        <h3>Praxis-Workflow</h3>
        <ol>
          <li>Fragestellung präzisieren und Zielgruppe definieren.</li>
          <li>Datenquelle auswählen und dokumentieren.</li>
          <li>Indikatoren berechnen und validieren.</li>
          <li>Ergebnisse visualisieren und interpretieren.</li>
          <li>Bericht mit Limitationen veröffentlichen.</li>
        </ol>

        <h3>Responsible-Metrics-Box</h3>
        <ul>
          <li>Verwenden Sie mehrere Indikatoren und erläutern Sie deren Grenzen.</li>
          <li>Kombinieren Sie quantitative Werte mit qualitativen Einschätzungen.</li>
        </ul>

        <h3>Quellen &amp; weiterführende Links</h3>
        <ul>
          <li><a href="https://www.dora.org/">https://www.dora.org/</a></li>
          <li><a href="https://www.leidenmanifesto.org/">https://www.leidenmanifesto.org/</a></li>
          <li><a href="https://www.crossref.org/">https://www.crossref.org/</a></li>
        </ul>
      </section>

      <section class="module-section" id="modul-2">
        <h2>Modul 2: Datenquellen &amp; Coverage: Woher kommen bibliometrische Zahlen?</h2>
        <div class="module-role-panel">
          <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
          <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
            <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
            <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
            <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
          </div>
          <div class="module-role-hints">
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Baut ein internes Standardblatt: „Welche Datenquelle für welche Frage?“
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Dokumentiert Coverage-Hinweise sichtbar im Report (z. B. als Methodik-Kasten).
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Vermeidet Tool-Mix ohne Erklärung: Wenn mehrere Quellen kombiniert werden, müsst ihr
              Dubletten/IDs klären.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Definiert früh den Zweck: Monitoring ≠ Bewertung. Die Datenquelle hängt am Ziel.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Für Governance: verlangt Standardangaben (Quelle, Zeitraum, Dokumenttypen, Limitationen).
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Wenn Ranking-Druck entsteht: nutzt Responsible-Metrics-Checks (Kontext + Multi-Indikator +
              qualitative Evidenz).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Wenn Zahlen nicht passen: prüfe zuerst Namensvarianten, Affiliations, Dokumenttypen und
              Zeitraum.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Nutze Kennzahlen in CVs nur mit kurzer Kontextzeile (Quelle + Zeitraum + Feld).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Für Themen-/Kooperationsanalysen können offene Quellen sehr nützlich sein – aber Ergebnisse
              immer plausibilisieren.
            </div>
          </div>
        </div>

        <h3>Lernziele</h3>
        <ul>
          <li>Die wichtigsten bibliometrischen Datenquellen unterscheiden.</li>
          <li>Verstehen, was „Coverage“ praktisch bedeutet.</li>
          <li>Erklären, warum Zahlen je nach Datenquelle unterschiedlich ausfallen können.</li>
          <li>Eine passende Datenquelle für eine konkrete Fragestellung auswählen und Limitationen kommunizieren.</li>
        </ul>

        <h3>Schlüsselbegriffe</h3>
        <ul>
          <li>
            <strong>Datenquelle:</strong> Ein System/Index, aus dem bibliometrische Daten stammen (z. B. kuratierte
            Zitationsdatenbank oder offene Metadateninfrastruktur).
          </li>
          <li>
            <strong>Coverage (Abdeckung):</strong> Welche Inhalte eine Datenquelle enthält (Zeitschriften,
            Konferenzen, Bücher, Sprachen, Länder, Jahre, Dokumenttypen).
          </li>
          <li>
            <strong>Indexierung:</strong> Wie Inhalte aufgenommen, strukturiert und verknüpft werden (z. B.
            Zitationslinks, Autor:innen, Institutionen).
          </li>
          <li>
            <strong>Kuratiert:</strong> Inhalte werden nach definierten Kriterien ausgewählt und redaktionell betreut.
          </li>
          <li>
            <strong>Offene Infrastruktur:</strong> Offene Daten/Metadaten (z. B. via API), die reproduzierbare Analysen
            ermöglichen, aber stark von Datenqualität abhängen.
          </li>
          <li>
            <strong>Bias:</strong> Systematische Verzerrung in Daten (z. B. Sprache, Region, Disziplin, Dokumenttyp),
            die Ergebnisse beeinflussen kann.
          </li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Bibliometrische Kennzahlen sind nur so gut wie ihre Datenbasis. Unterschiedliche Datenquellen erfassen
          unterschiedliche Publikationen, Sprachen und Dokumenttypen – und verknüpfen Zitationen nicht immer gleich.
          Deshalb können zwei seriöse Systeme für dieselbe Einheit verschiedene Publikations- und Zitierzahlen zeigen.
          In diesem Modul lernst du, welche Quellen es gibt, wie Coverage entsteht und wie du Ergebnisse transparent und
          verantwortungsvoll kommunizierst.
        </p>

        <h3>Vertiefung: Die wichtigsten Datenquellen im Überblick</h3>
        <p>In der Bibliometrie gibt es grob drei Familien von Datenquellen:</p>
        <h4>1) Kuratierte Zitationsdatenbanken (z. B. WoS, Scopus)</h4>
        <ul>
          <li>Vorteil: definierte Selektions- und Indexierungslogik, konsistente Metadaten, stabile Auswertungen.</li>
          <li>Risiko: nicht jede Disziplin, Sprache oder Publikationsform ist gleich gut abgedeckt.</li>
        </ul>
        <h4>2) Offene Datenquellen (z. B. OpenAlex, Crossref)</h4>
        <ul>
          <li>Vorteil: offen zugänglich, API-basiert, reproduzierbar.</li>
          <li>Risiko: Metadatenqualität ist heterogen; Coverage kann je nach Bereich schwanken.</li>
        </ul>
        <h4>3) Suchmaschinen/Plattformen (z. B. Google Scholar)</h4>
        <ul>
          <li>Vorteil: häufig sehr breite Abdeckung.</li>
          <li>Risiko: begrenzte Transparenz, schwierig für belastbare Evaluation.</li>
        </ul>

        <h4>Warum unterscheiden sich Zahlen je nach Quelle?</h4>
        <ul>
          <li>Unterschiedliche Coverage (welche Journals/Konferenzen/Bücher enthalten sind)</li>
          <li>Unterschiedliche Dokumenttypen (z. B. Proceedings, Preprints)</li>
          <li>Unterschiedliche Indexierung (Zitationsverknüpfungen, Duplikate, Normalisierung)</li>
        </ul>

        <p><strong>Merksatz:</strong> Eine Kennzahl ohne Angabe der Datenquelle ist unvollständig.</p>

        <h4>Mini-Checkliste für jeden Report</h4>
        <ul>
          <li>Datenquelle(n): …</li>
          <li>Zeitraum: …</li>
          <li>Dokumenttypen: …</li>
          <li>Limitationen/Coverage-Hinweise: …</li>
          <li>Reproduzierbarkeit: Query/Datum dokumentiert: Ja/Nein</li>
        </ul>

        <h3>Typische Fehlinterpretationen</h3>
        <ul>
          <li>
            <strong>Mythos:</strong> „Wenn zwei Quellen unterschiedliche Zahlen liefern, ist eine falsch.“
            <strong>Korrektur:</strong> Unterschiede entstehen oft durch Coverage, Dokumenttypen und
            Indexierungslogik.
          </li>
          <li>
            <strong>Mythos:</strong> „Mehr Coverage bedeutet automatisch bessere Bibliometrie.“
            <strong>Korrektur:</strong> Transparenz, Datenqualität und definierte Regeln sind entscheidend.
          </li>
          <li>
            <strong>Mythos:</strong> „Wir können jede Disziplin gleich vergleichen.“
            <strong>Korrektur:</strong> Coverage und Zitationskulturen unterscheiden sich stark.
          </li>
          <li>
            <strong>Mythos:</strong> „Tools liefern neutrale Wahrheit.“
            <strong>Korrektur:</strong> Tools spiegeln Entscheidungen über Indexierung und Metadatenqualität wider.
          </li>
        </ul>

        <h3>Hinweise nach Zielrolle</h3>
        <div class="module-subsection-grid">
          <div>
            <h4>Bibliothek</h4>
            <ul>
              <li>Baut ein internes Standardblatt: „Welche Datenquelle für welche Frage?“</li>
              <li>Dokumentiert Coverage-Hinweise sichtbar im Report (z. B. als Methodik-Kasten).</li>
              <li>
                Vermeidet Tool-Mix ohne Erklärung: Wenn mehrere Quellen kombiniert werden, müsst ihr Dubletten/IDs
                klären.
              </li>
            </ul>
          </div>
          <div>
            <h4>Research Office</h4>
            <ul>
              <li>Definiert früh den Zweck: Monitoring ≠ Bewertung. Die Datenquelle hängt am Ziel.</li>
              <li>Für Governance: verlangt Standardangaben (Quelle, Zeitraum, Dokumenttypen, Limitationen).</li>
              <li>
                Wenn Ranking-Druck entsteht: nutzt Responsible-Metrics-Checks (Kontext + Multi-Indikator + qualitative
                Evidenz).
              </li>
            </ul>
          </div>
          <div>
            <h4>Forschende</h4>
            <ul>
              <li>Wenn Zahlen nicht passen: prüfe zuerst Namensvarianten, Affiliations, Dokumenttypen und Zeitraum.</li>
              <li>Nutze Kennzahlen in CVs nur mit kurzer Kontextzeile (Quelle + Zeitraum + Feld).</li>
              <li>
                Für Themen-/Kooperationsanalysen können offene Quellen sehr nützlich sein – aber Ergebnisse immer
                plausibilisieren.
              </li>
            </ul>
          </div>
        </div>

        <h3>Praxis-Workflow: Datenquelle auswählen</h3>
        <ol>
          <li>Frage klären: Monitoring, Reporting, Trendanalyse oder Evaluation?</li>
          <li>Analyseobjekt definieren: Person/Institut/Thema + Zeitraum + Publikationstypen.</li>
          <li>Kandidaten-Datenquellen auswählen (kuratierte DB vs. offen vs. Suchmaschine).</li>
          <li>Coverage prüfen: Disziplin, Sprache, Bücher/Proceedings, regionale Literatur.</li>
          <li>Testabfrage durchführen und plausibilisieren (Stichprobe gegen bekannte Publikationen).</li>
          <li>Bereinigung planen: IDs, Dubletten, Affiliations, Namensvarianten.</li>
          <li>Ergebnisbericht: immer mit Datenbasis + Limitationen + Datum der Abfrage.</li>
        </ol>

        <h3>Responsible-Metrics-Box: Minimum-Transparenz für Datenquellen</h3>
        <ul>
          <li>Nenne immer Datenquelle(n), Zeitraum und Dokumenttypen.</li>
          <li>
            Wenn Zahlen verglichen werden: erkläre Coverage-Unterschiede und warum der Vergleich sinnvoll ist (oder
            nicht).
          </li>
          <li>Vermeide mechanische Entscheidungen anhand einer einzigen Quelle oder Kennzahl.</li>
          <li>Nutze Bibliometrie als Hinweis-System: Ergebnisse sollten plausibilisiert und kontextualisiert werden.</li>
        </ul>

        <details>
          <summary>Übungen</summary>
          <div class="details-content">
            <h4>Level 1</h4>
            <ol>
              <li>
                <strong>M02-L1-Q1:</strong> Was bedeutet „Coverage“ in einer bibliometrischen Datenquelle?
                <ul>
                  <li>Wie viele Personen an einem Institut arbeiten.</li>
                  <li>Welche Publikationsarten, Disziplinen, Sprachen und Jahre in der Quelle enthalten sind.</li>
                  <li>Wie hoch der Journal Impact Factor ist.</li>
                </ul>
                <p><strong>Lösung:</strong> Welche Publikationsarten, Disziplinen, Sprachen und Jahre in der Quelle enthalten sind.</p>
              </li>
              <li>
                <strong>M02-L1-Q2:</strong> Welche Aussage ist am besten im Sinne von Responsible Metrics?
                <ul>
                  <li>Ein Report braucht keine Methodik, Hauptsache die Zahl ist klar.</li>
                  <li>Zu jeder Kennzahl gehören Datenquelle, Zeitraum und Limitationen.</li>
                  <li>Wenn zwei Tools verschieden zählen, nimmt man einfach den höheren Wert.</li>
                </ul>
                <p><strong>Lösung:</strong> Zu jeder Kennzahl gehören Datenquelle, Zeitraum und Limitationen.</p>
              </li>
              <li>
                <strong>M02-L1-Q3:</strong> Wähle die defensibelste Erklärung: Warum zeigt Quelle A mehr Publikationen als Quelle B?
                <ul>
                  <li>Quelle A hat wahrscheinlich mehr Dokumenttypen oder breitere Abdeckung indexiert.</li>
                  <li>Quelle B ist automatisch falsch.</li>
                  <li>Das Institut hat heimlich Publikationen gelöscht.</li>
                </ul>
                <p><strong>Lösung:</strong> Quelle A hat wahrscheinlich mehr Dokumenttypen oder breitere Abdeckung indexiert.</p>
              </li>
              <li>
                <strong>M02-L1-Q4:</strong> Was ist ein sinnvoller erster Schritt, bevor du zwei Datenquellen vergleichst?
                <ul>
                  <li>Sofort ein Ranking erstellen.</li>
                  <li>Dokumenttypen und Zeitraum angleichen und Coverage prüfen.</li>
                  <li>Nur nach Gefühl entscheiden, welche Quelle besser ist.</li>
                </ul>
                <p><strong>Lösung:</strong> Dokumenttypen und Zeitraum angleichen und Coverage prüfen.</p>
              </li>
              <li>
                <strong>M02-L1-Q5:</strong> Warum ist die Datenquelle in jedem Bibliometrie-Report Pflichtangabe?
                <ul>
                  <li>Weil Zahlen nur im Kontext der Coverage interpretierbar sind.</li>
                  <li>Weil sonst das Layout zu leer ist.</li>
                  <li>Weil Kennzahlen überall identisch sind.</li>
                </ul>
                <p><strong>Lösung:</strong> Weil Zahlen nur im Kontext der Coverage interpretierbar sind.</p>
              </li>
            </ol>

            <h4>Level 2</h4>
            <ol>
              <li>
                <strong>M02-L2-Q1:</strong> Interpretation: Zwei Quellen liefern unterschiedliche Publikationszahlen. Was schreibst du in den
                Report (2–3 Sätze, defensiv formuliert)?
                <table>
                  <thead>
                    <tr>
                      <th>Einheit</th>
                      <th>Zeitraum</th>
                      <th>Quelle</th>
                      <th>Publikationen</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Institut A</td>
                      <td>2021–2024</td>
                      <td>Quelle 1</td>
                      <td>120</td>
                    </tr>
                    <tr>
                      <td>Institut A</td>
                      <td>2021–2024</td>
                      <td>Quelle 2</td>
                      <td>155</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  <strong>Lösung:</strong> Die unterschiedlichen Werte sind wahrscheinlich durch abweichende Coverage erklärbar. Für die
                  Interpretation ist entscheidend, welche Datenquelle zur Fragestellung passt. Im Report werden
                  Datenquelle, Zeitraum, Dokumenttypen und Limitationen transparent dokumentiert.
                </p>
              </li>
              <li>
                <strong>M02-L2-Q2:</strong> Quelle auswählen: Du brauchst ein reproduzierbares Monitoring-Dashboard ohne Paywall. Welche
                Datenquelle passt am ehesten und welche Einschränkung nennst du?
                <p>
                  <strong>Lösung:</strong> OpenAlex (API-basiert, offen, reproduzierbar) ist naheliegend. Einschränkung: Coverage und
                  Metadatenqualität können variieren; deshalb braucht es Plausibilisierung und Dokumentation der
                  Abfrageparameter.
                </p>
              </li>
              <li>
                <strong>M02-L2-Q3:</strong> Quality Check: Nenne 3 Prüfungen, die du bei einer Publikationsliste aus einer Datenquelle machst,
                bevor du Kennzahlen berichtest.
                <p>
                  <strong>Lösung:</strong> Beispiele: Dublettenprüfung, Namensvarianten/IDs plausibilisieren, Affiliations prüfen,
                  Dokumenttypen filtern, Zeitraum korrekt setzen.
                </p>
              </li>
            </ol>

            <h4>Level 3</h4>
            <ol>
              <li>
                <strong>M02-L3-CASE:</strong> Mini-Case: Du sollst für eine Fakultät einen Vergleich „Publikationsoutput 2020–2024“ erstellen.
                Definiere deine Datenbasis (Quelle(n), Dokumenttypen, Zeitraum) und formuliere 4 Limitationen/Warnhinweise.
                <p><strong>Deliverable:</strong> Methodik-Kasten + 4 Limitationen (Bulletpoints).</p>
              </li>
            </ol>
          </div>
        </details>

        <h3>Quellen &amp; weiterführende Links</h3>
        <ul>
          <li>
            Clarivate: Web of Science Core Collection – Content collection and indexing process:
            <a
              href="https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/web-of-science-core-collection/content-collection-and-indexing-process/"
              >https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/web-of-science-core-collection/content-collection-and-indexing-process/</a
            >
          </li>
          <li>
            Elsevier: Scopus Content Coverage Guide (PDF):
            <a
              href="https://assets.ctfassets.net/o78em1y1w4i4/EX1iy8VxBeQKf8aN2XzOp/c36f79db25484cb38a5972ad9a5472ec/Scopus_ContentCoverage_Guide_WEB.pdf"
              >https://assets.ctfassets.net/o78em1y1w4i4/EX1iy8VxBeQKf8aN2XzOp/c36f79db25484cb38a5972ad9a5472ec/Scopus_ContentCoverage_Guide_WEB.pdf</a
            >
          </li>
          <li>
            OpenAlex Documentation: API Overview:
            <a href="https://docs.openalex.org/how-to-use-the-api/api-overview"
              >https://docs.openalex.org/how-to-use-the-api/api-overview</a
            >
          </li>
          <li>
            Crossref Documentation: Metadata Retrieval:
            <a href="https://www.crossref.org/documentation/retrieve-metadata/"
              >https://www.crossref.org/documentation/retrieve-metadata/</a
            >
          </li>
          <li>
            CWTS (Leiden): Bibliometrics for Research Management (PDF):
            <a href="https://www.cwts.nl/pdf/CWTS_bibliometrics.pdf">https://www.cwts.nl/pdf/CWTS_bibliometrics.pdf</a>
          </li>
          <li>
            Gusenbauer &amp; Haddaway (2020): Suitable academic search systems (PubMed):
            <a href="https://pubmed.ncbi.nlm.nih.gov/31614060/">https://pubmed.ncbi.nlm.nih.gov/31614060/</a>
          </li>
          <li>
            Gusenbauer (2024): Beyond Google Scholar, Scopus, and WoS:
            <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1729"
              >https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1729</a
            >
          </li>
        </ul>

        <h3>Weiterführende Lektüre</h3>
        <ul>
          <li>
            López-Cózar (2018): Google Scholar as bibliographic tool (arXiv PDF):
            <a href="https://arxiv.org/pdf/1806.06351">https://arxiv.org/pdf/1806.06351</a>
          </li>
          <li>
            Dimensions Support: What is covered in Publications?:
            <a href="https://plus.dimensions.ai/support/solutions/articles/23000018859-what-exactly-is-covered-in-the-publications-in-dimensions-"
              >https://plus.dimensions.ai/support/solutions/articles/23000018859-what-exactly-is-covered-in-the-publications-in-dimensions-</a
            >
          </li>
        </ul>
      </section>

      <section class="module-section" id="modul-3">
        <h2>Modul 3: Zitationen verstehen: Was zählen wir – und was bedeutet es (nicht)?</h2>
        <ul class="module-meta">
          <li><strong>Schwierigkeit:</strong> 1</li>
          <li><strong>Geschätzte Lesezeit:</strong> 20 Minuten</li>
          <li><strong>Zielgruppen:</strong> Bibliothek, Forschungsreferat, Forschende</li>
          <li><strong>Voraussetzungen:</strong> Modul 1, Modul 2</li>
        </ul>

        <h3>Lernziele</h3>
        <ul>
          <li>Zitationen als Signal (nicht als Beweis) verstehen.</li>
          <li>Zitationsfenster und Zeitdynamiken erklären.</li>
          <li>Selbstzitate und Zitationskontext korrekt einordnen.</li>
          <li>Zitationskennzahlen transparent berichten.</li>
        </ul>

        <h3>Schlüsselbegriffe</h3>
        <ul>
          <li>
            <strong>Zitation (Citation):</strong> Verweis auf eine Publikation; Signal für Resonanz, nicht automatisch Qualität.
          </li>
          <li><strong>Zitationszählung:</strong> Anzahl Zitationen in einer Datenquelle innerhalb eines Zeitraums.</li>
          <li><strong>Zitationsfenster:</strong> Zeitraum, in dem Zitationen gezählt werden (z. B. 2, 4, 5 oder 10 Jahre).</li>
          <li><strong>Zitationsverzögerung:</strong> Zeit, bis eine Publikation zitiert wird.</li>
          <li><strong>Selbstzitation:</strong> Zitationen, bei denen sich Autor:innen selbst zitieren.</li>
          <li><strong>Zitationskontext:</strong> Verwendung der Zitation (zustimmend, neutral, kritisch).</li>
          <li><strong>Feldunterschiede:</strong> Unterschiede in Publikations- und Zitationskulturen.</li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Eine Zitation ist ein Verweis von einer Publikation auf eine andere. Zitationszahlen werden oft genutzt, um
          Resonanz oder Sichtbarkeit zu beschreiben. Aber: Zitationen sind kein direkter Qualitätsbeweis. Sie hängen vom
          Fachgebiet, vom Alter eines Artikels, vom Publikationstyp und von der Datenquelle ab. Zusätzlich sind nicht alle
          Zitationen „Lob“ – manche sind neutral oder kritisch. Deshalb brauchst du beim Interpretieren immer Kontext:
          Zitationsfenster, Fachgebiet, Datenbasis und klare Limitationen.
        </p>

        <h3>Vertiefung: Wie Zitationsdaten entstehen – und warum sie tückisch sein können</h3>
        <ol>
          <li>
            <strong>Zeitdynamik (Alter zählt):</strong> Neuere Publikationen hatten weniger Zeit, Zitationen zu sammeln. Darum ist
            das Zitationsfenster ein zentraler Parameter.
          </li>
          <li>
            <strong>Verteilung:</strong> Zitationen sind stark ungleich verteilt; Durchschnittswerte können irreführend sein.
          </li>
          <li>
            <strong>Dokumenttyp-Effekt:</strong> Reviews und Methodenpapiere werden oft häufiger zitiert als Spezialstudien.
          </li>
          <li>
            <strong>Selbstzitate:</strong> Legitimes Anschlusszitat, kann Kennzahlen verzerren. Gute Praxis: mit und ohne
            Selbstzitate ausweisen.
          </li>
          <li>
            <strong>Zitationskontext:</strong> Zitationen können zustimmend, neutral oder kritisch sein; nicht jede Zitation ist
            „positiv“.
          </li>
        </ol>

        <p>
          <strong>Praktische Konsequenz:</strong> Zitationszahlen immer mit Datenquelle, Abfragedatum, Zeitraum/Zitationsfenster,
          Dokumenttypen, Selbstzitate-Regel und Limitationen dokumentieren.
        </p>

        <h3>Typische Fehlinterpretationen</h3>
        <ul>
          <li>
            <strong>„Viele Zitationen beweisen hohe Qualität.“</strong> Zitationen sind ein Signal, beeinflusst durch Feld, Alter,
            Dokumenttyp und Kontext.
          </li>
          <li>
            <strong>„Neuere Publikationen sind schwächer.“</strong> Oft ist das ein Zeitfenster-Effekt; Vergleiche brauchen
            passende Fenster.
          </li>
          <li>
            <strong>„Selbstzitate sind immer Betrug.“</strong> Häufig legitim, wichtig ist Transparenz.
          </li>
          <li>
            <strong>„Alle Zitationen sind positiv.“</strong> Zitationen können neutral oder kritisch sein.
          </li>
          <li>
            <strong>„Man kann jedes Fachgebiet direkt vergleichen.“</strong> Zitationskulturen unterscheiden sich stark.
          </li>
        </ul>

        <h3>Hinweise nach Zielrolle</h3>
        <div class="module-subsection-grid">
          <div>
            <h4>Bibliothek</h4>
            <ul>
              <li>In Beratungen: zuerst Datenbasis prüfen, dann interpretieren.</li>
              <li>Bei Reports: Zitationen immer mit Zitationsfenster und Abfragedatum ausweisen.</li>
              <li>Wenn möglich: Standardformulierung für Zitationszahlen nutzen.</li>
            </ul>
          </div>
          <div>
            <h4>Forschungsreferat</h4>
            <ul>
              <li>Zitationszahlen als Trend- und Kontextsignal nutzen, nicht als Ranking.</li>
              <li>Bestehe auf Mindest-Transparenz: Quelle, Fenster, Selbstzitate, Dokumenttypen.</li>
              <li>Bei Entscheidungen: Multi-Methoden-Ansatz (quantitativ + qualitativ).</li>
            </ul>
          </div>
          <div>
            <h4>Forschende</h4>
            <ul>
              <li>Vergleiche nur innerhalb sinnvoller Gruppen (Fach, Karrierestufe, Publikationstyp, Alter).</li>
              <li>Kontextzeile mit Quelle + Zeitraum + Fenster ergänzen.</li>
              <li>Bei Peaks prüfen, ob Reviews/Methodenpapiere oder Datenartefakte vorliegen.</li>
            </ul>
          </div>
        </div>

        <h3>Praxis-Workflow: Zitationen korrekt berichten</h3>
        <ol>
          <li>Ziel klären: Monitoring, Kontext im CV, Report oder Evaluation?</li>
          <li>Datenquelle festlegen (und begründen) + Abfragedatum dokumentieren.</li>
          <li>Zitationsfenster definieren und konsistent halten.</li>
          <li>Dokumenttypen festlegen (z. B. Article/Review getrennt ausweisen).</li>
          <li>Selbstzitate-Regel definieren (mit/ohne) und transparent berichten.</li>
          <li>Ergebnisse plausibilisieren (Stichprobe, Ausreißer prüfen, Kontext beachten).</li>
          <li>Methodik-Kasten + Limitationen + Responsible-Metrics-Hinweisbox einfügen.</li>
        </ol>

        <h3>Responsible Metrics: Zitationen</h3>
        <ul>
          <li>Zitationen sind Kontextsignale, keine automatische Qualitätsnote.</li>
          <li>Zitationsfenster und Alter sind Pflichtkontext für jede Interpretation.</li>
          <li>Dokumenttypen und Fachgebiet berücksichtigen.</li>
          <li>Selbstzitate transparent behandeln.</li>
          <li>Bei Evaluationen: Zitationen nur zusammen mit qualitativen Verfahren nutzen.</li>
        </ul>

        <details>
          <summary>Übungen</summary>
          <div class="details-content">
            <h4>Level 1</h4>
            <ol>
              <li>
                <strong>M03-L1-Q1:</strong> Welche Aussage zu Zitationen ist am defensibelsten?
                <ul>
                  <li>Viele Zitationen beweisen, dass die Forschung qualitativ besser ist.</li>
                  <li>Zitationen können Sichtbarkeit anzeigen, müssen aber mit Kontext interpretiert werden.</li>
                  <li>Zitationen sind wertlos und sollten nie verwendet werden.</li>
                </ul>
                <p><strong>Lösung:</strong> Zitationen können Sichtbarkeit anzeigen, müssen aber mit Kontext interpretiert werden.</p>
              </li>
              <li>
                <strong>M03-L1-Q2:</strong> Was ist ein Zitationsfenster (Citation Window)?
                <ul>
                  <li>Die Anzahl Referenzen im Literaturverzeichnis.</li>
                  <li>Der Zeitraum, in dem Zitationen gezählt werden (z. B. 4 Jahre).</li>
                  <li>Die Anzahl Publikationen pro Jahr.</li>
                </ul>
                <p><strong>Lösung:</strong> Der Zeitraum, in dem Zitationen gezählt werden (z. B. 4 Jahre).</p>
              </li>
              <li>
                <strong>M03-L1-Q3:</strong> Welche Aussage zu Selbstzitaten passt am besten?
                <ul>
                  <li>Selbstzitate sind immer Betrug.</li>
                  <li>Selbstzitate können legitim sein, sollten aber je nach Zweck transparent behandelt werden.</li>
                  <li>Selbstzitate zählen nie in Datenquellen.</li>
                </ul>
                <p><strong>Lösung:</strong> Selbstzitate können legitim sein, sollten aber je nach Zweck transparent behandelt werden.</p>
              </li>
              <li>
                <strong>M03-L1-Q4:</strong> Welche Aussage ist korrekt?
                <ul>
                  <li>Alle Zitationen sind positive Anerkennung.</li>
                  <li>Zitationen können auch kritisch oder neutral sein.</li>
                  <li>Negative Zitationen sind unmöglich.</li>
                </ul>
                <p><strong>Lösung:</strong> Zitationen können auch kritisch oder neutral sein.</p>
              </li>
              <li>
                <strong>M03-L1-Q5:</strong> Warum sind Vergleiche zwischen Fachgebieten schwierig?
                <ul>
                  <li>Weil Zitations- und Publikationskulturen je nach Fach unterschiedlich sind.</li>
                  <li>Weil alle Fächer identisch publizieren.</li>
                  <li>Weil Datenquellen immer vollständig sind.</li>
                </ul>
                <p><strong>Lösung:</strong> Weil Zitations- und Publikationskulturen je nach Fach unterschiedlich sind.</p>
              </li>
            </ol>

            <h4>Level 2</h4>
            <ol>
              <li>
                <strong>M03-L2-Q1:</strong> Zitationsfenster-Effekt: Welche Interpretation ist korrekt?
                <table>
                  <thead>
                    <tr>
                      <th>Paper</th>
                      <th>Year</th>
                      <th>Citations in 2024 (cum.)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>A</td>
                      <td>2019</td>
                      <td>45</td>
                    </tr>
                    <tr>
                      <td>B</td>
                      <td>2023</td>
                      <td>8</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  <strong>Lösung:</strong> Paper A hatte mehr Zeit, Zitationen zu sammeln. Ein direkter Vergleich ohne gleiches
                  Zitationsfenster oder Altersklassen ist unfair. Für einen faireren Vergleich sollte man Zitationen
                  innerhalb eines definierten Fensters betrachten.
                </p>
              </li>
              <li>
                <strong>M03-L2-Q2:</strong> Selbstzitate: Formuliere eine Report-Zeile (1–2 Sätze), die Zitationen mit und ohne Selbstzitate
                transparent ausweist.
                <table>
                  <thead>
                    <tr>
                      <th>Einheit</th>
                      <th>Zeitraum</th>
                      <th>Zitationen (gesamt)</th>
                      <th>Zitationen (ohne Selbstzitate)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Institut A</td>
                      <td>2020–2024</td>
                      <td>980</td>
                      <td>840</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  <strong>Lösung:</strong> Im Zeitraum 2020–2024 wurden 980 Zitationen gezählt; ohne Selbstzitate sind es 840. Die Differenz
                  wird zur Transparenz separat ausgewiesen.
                </p>
              </li>
              <li>
                <strong>M03-L2-Q3:</strong> Dokumenttyp-Effekt: Warum kann ein Review-Artikel Zitationszahlen verzerren? Nenne 2 Gründe.
                <p>
                  <strong>Lösung:</strong> Reviews bündeln Literatur und werden oft als Einstieg zitiert. Außerdem werden Methoden- und
                  Übersichtsarbeiten quer über Teilfelder zitiert, was Vergleiche verzerren kann.
                </p>
              </li>
            </ol>

            <h4>Level 3</h4>
            <ol>
              <li>
                <strong>M03-L3-CASE:</strong> Mini-Case: Formuliere einen Methodik-Kasten (Quelle, Abfragedatum, Zitationsfenster,
                Dokumenttypen, Umgang mit Selbstzitaten) und 4 Limitationen/Warnhinweise zur Interpretation.
              </li>
            </ol>
          </div>
        </details>

        <h3>Quellen</h3>
        <ul>
          <li>
            Garfield, E. (1955). Citation Indexes for Science. Science (PDF).
            <a href="https://garfield.library.upenn.edu/papers/science1955.pdf"
              >https://garfield.library.upenn.edu/papers/science1955.pdf</a
            >
          </li>
          <li>
            Hicks, D. et al. (2015). The Leiden Manifesto for research metrics. Nature.
            <a href="https://www.nature.com/articles/520429a">https://www.nature.com/articles/520429a</a>
          </li>
          <li>
            DORA (2012). San Francisco Declaration on Research Assessment.
            <a href="https://sfdora.org/read/">https://sfdora.org/read/</a>
          </li>
          <li>
            Wilsdon, J. et al. (2015). The Metric Tide (PDF).
            <a href="https://www.ukri.org/wp-content/uploads/2021/12/RE-151221-TheMetricTideFullReport2015.pdf"
              >https://www.ukri.org/wp-content/uploads/2021/12/RE-151221-TheMetricTideFullReport2015.pdf</a
            >
          </li>
          <li>
            Waltman, L. (2016). A review of the literature on citation impact indicators. Journal of Informetrics.
            <a href="https://www.sciencedirect.com/science/article/pii/S1751157715300900"
              >https://www.sciencedirect.com/science/article/pii/S1751157715300900</a
            >
          </li>
          <li>
            Fowler, J. H., &amp; Aksnes, D. W. (2007). Does self-citation pay? Scientometrics.
            <a href="https://link.springer.com/article/10.1007/s11192-007-1777-2"
              >https://link.springer.com/article/10.1007/s11192-007-1777-2</a
            >
          </li>
          <li>
            Moed, H. F. (2007). Developing Bibliometric Indicators of Research Performance (CWTS report, PDF).
            <a href="https://www.cwts.nl/pdf/nwo_inf_final_report_v_210207.pdf"
              >https://www.cwts.nl/pdf/nwo_inf_final_report_v_210207.pdf</a
            >
          </li>
          <li>
            Xu, J. et al. (2015). Citation Sentiment Analysis in Clinical Trial Papers (PMC).
            <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC4765697/">https://pmc.ncbi.nlm.nih.gov/articles/PMC4765697/</a>
          </li>
          <li>
            Song, D. et al. (2022). Quantifying characteristics of negative citations. Information Processing &amp; Management.
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457322001108"
              >https://www.sciencedirect.com/science/article/abs/pii/S0306457322001108</a
            >
          </li>
        </ul>

        <h3>Weiterführende Lektüre</h3>
        <ul>
          <li>
            Waltman (Preprint). A review of the literature on citation impact indicators (arXiv).
            <a href="https://arxiv.org/abs/1507.02099">https://arxiv.org/abs/1507.02099</a>
          </li>
        </ul>
      </section>
    </main>
    <script src="role-toggle.js" defer></script>
  </body>
</html>
