<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Einführung Bibliometrie – Lehrgang</title>
    <link rel="stylesheet" href="styles.css" />
    <script src="navigation.js" defer></script>
  </head>
  <body>
    <header class="site-header">
      <div class="brand">Einführung Bibliometrie</div>
      <button class="nav-toggle" type="button" aria-expanded="false" aria-controls="primary-navigation">
        <span class="nav-toggle-label">Menü</span>
        <span class="nav-toggle-icon" aria-hidden="true">
          <span class="nav-toggle-bar"></span>
          <span class="nav-toggle-bar"></span>
          <span class="nav-toggle-bar"></span>
        </span>
      </button>
      <nav class="site-nav" id="primary-navigation" aria-label="Hauptnavigation">
        <a href="index.html">Start</a>
        <a class="active" href="lehrgang.html">Lehrgang</a>
        <a href="uebungen.html">Übungen</a>
        <a href="fallstudien.html">Fallstudien</a>
        <a href="tools-datenquellen.html">Tools &amp; Datenquellen</a>
        <a href="responsible-metrics.html">Responsible Metrics</a>
        <a href="glossar.html">Glossar</a>
        <a href="downloads-vorlagen.html">Downloads &amp; Vorlagen</a>
        <a href="faq.html">FAQ</a>
      </nav>
    </header>
    <main class="content">
      <h1>Lehrgang</h1>
      <p>
        Hier findest du die Module 1–4 des Lehrgangs. Nutze die Hinweise für deine Rolle, um die
        wichtigsten Punkte gezielt zu vertiefen.
      </p>
      <figure class="page-illustration">
        <img
          src="assets/workflow-diagramm-biblometrie-prozess.png"
          alt="Workflow-Diagramm des bibliometrischen Analyseprozesses"
          loading="lazy"
        />
        <figcaption>
          Der Prozess zeigt die wichtigsten Schritte von der Fragestellung bis zum Bericht.
        </figcaption>
      </figure>
      <nav class="module-nav" aria-label="Modul-Navigation">
        <p class="module-nav-label">Module auswählen:</p>
        <div class="table-responsive">
          <table class="table module-table">
            <thead>
              <tr>
                <th scope="col">Modul</th>
                <th scope="col">Modulname</th>
                <th scope="col">Kurzbeschreibung</th>
                <th scope="col">Schwierigkeit</th>
                <th scope="col">Lesezeit</th>
                <th scope="col">Start</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td data-label="Modul">1</td>
                <td data-label="Modulname">Grundlagen der Bibliometrie</td>
                <td data-label="Kurzbeschreibung">
                  Zentrale Begriffe, Zitationslogik und verantwortungsvoller Einsatz von Kennzahlen.
                </td>
                <td data-label="Schwierigkeit">Beginner</td>
                <td data-label="Lesezeit">45 Minuten</td>
                <td data-label="Start">
                  <a class="start-button" href="#modul-1">Start</a>
                </td>
              </tr>
              <tr>
                <td data-label="Modul">2</td>
                <td data-label="Modulname">Publikationsdaten und Quellen</td>
                <td data-label="Kurzbeschreibung">
                  Auswahl, Abdeckung und Qualität von Datenquellen für bibliometrische Analysen.
                </td>
                <td data-label="Schwierigkeit">Beginner</td>
                <td data-label="Lesezeit">50 Minuten</td>
                <td data-label="Start">
                  <a class="start-button" href="#modul-2">Start</a>
                </td>
              </tr>
              <tr>
                <td data-label="Modul">3</td>
                <td data-label="Modulname">Zitationsindikatoren</td>
                <td data-label="Kurzbeschreibung">
                  Zitationsmetriken verstehen, sauber berichten und im Kontext interpretieren.
                </td>
                <td data-label="Schwierigkeit">Beginner</td>
                <td data-label="Lesezeit">55 Minuten</td>
                <td data-label="Start">
                  <a class="start-button" href="#modul-3">Start</a>
                </td>
              </tr>
              <tr>
                <td data-label="Modul">4</td>
                <td data-label="Modulname">Metriken für Autor:innen</td>
                <td data-label="Kurzbeschreibung">
                  Autor:innenmetriken einordnen und fair im Berichtskontext einsetzen.
                </td>
                <td data-label="Schwierigkeit">2</td>
                <td data-label="Lesezeit">25 Minuten</td>
                <td data-label="Start">
                  <a class="start-button" href="#modul-4">Start</a>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
      </nav>

      <section class="module-section" id="modul-1" aria-labelledby="heading-modul-1">
        <h2 id="heading-modul-1">Modul 1: Grundlagen der Bibliometrie</h2>
        <ul class="module-meta">
          <li><strong>Schwierigkeit:</strong> Beginner</li>
          <li><strong>Geschätzte Lesezeit:</strong> 45 Minuten</li>
          <li><strong>Zielgruppen:</strong> Bibliothek, Research Office, Forschende</li>
          <li><strong>Voraussetzungen:</strong> Keine</li>
        </ul>
        <div class="module-role-panel">
          <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
          <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
            <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
            <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
            <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
          </div>
          <div class="module-role-hints">
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Klärt mit dem Team, welche bibliometrischen Basisbegriffe in Schulungen konsistent
              verwendet werden sollen.
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Notiert typische Nutzerfragen, um spätere Beratungsangebote daran auszurichten.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Haltet fest, welche Kennzahlen für interne Reports wirklich benötigt werden.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Prüft früh, welche Datenquellen für zentrale Entscheidungen akzeptiert sind.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Überlegt, welche Indikatoren eure Arbeit sinnvoll ergänzen, ohne sie zu reduzieren.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Sammelt Beispiele, wo Zitationszahlen missverstanden wurden, um gegenzusteuern.
            </div>
          </div>
        </div>

        <h3>Lernziele</h3>
        <ul>
          <li>Grundbegriffe der Bibliometrie erklären</li>
          <li>Zitationsdaten als Indikatoren einordnen</li>
          <li>Einsatzbereiche und Grenzen benennen</li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Bibliometrie untersucht wissenschaftliche Kommunikation anhand von Publikations- und
          Zitationsdaten. In diesem Modul lernen Sie, warum Zitationen als Hinweis auf Rezeption dienen,
          aber nicht mit Qualität gleichgesetzt werden dürfen. Wir betrachten typische Fragestellungen wie
          Forschungsleistung messen, Themenfelder beobachten oder Kooperationen sichtbar machen. Zugleich
          klären wir Begriffe wie Publikationstypen, Zitationsfenster, Datenbanken und die Rolle von
          Referenzen. Wir unterscheiden deskriptive Analysen von evaluativen Anwendungen und besprechen,
          welche Entscheidungen auf welcher Evidenz beruhen sollten. Ein besonderer Fokus liegt auf
          verantwortungsvollem Umgang mit Kennzahlen: Indikatoren sind Werkzeuge zur Orientierung, keine
          Urteile. Am Ende können Sie die Rolle der Bibliometrie im Forschungsmanagement einordnen und
          erkennen, welche Datenbasis für valide Aussagen nötig ist.
        </p>

        <h3>Vertiefung</h3>
        <ul>
          <li>Zentrale Begriffe und Definitionen sammeln und mit Beispielen illustrieren.</li>
          <li>Begrenzen, welche Aussagen mit den gewählten Daten tatsächlich möglich sind.</li>
          <li>Ein kurzes Reflexionsprotokoll zu Annahmen, Datenlücken und Bias erstellen.</li>
        </ul>

        <h4>Praxis-Workflow</h4>
        <ol>
          <li>Fragestellung präzisieren und Zielgruppe definieren.</li>
          <li>Datenquelle auswählen und dokumentieren.</li>
          <li>Indikatoren berechnen und validieren.</li>
          <li>Ergebnisse visualisieren und interpretieren.</li>
          <li>Bericht mit Limitationen veröffentlichen.</li>
        </ol>

        <h4>Responsible-Metrics-Box</h4>
        <ul>
          <li>Verwenden Sie mehrere Indikatoren und erläutern Sie deren Grenzen.</li>
          <li>Kombinieren Sie quantitative Werte mit qualitativen Einschätzungen.</li>
        </ul>

        <h3>Typische Fehlinterpretationen</h3>
        <ul>
          <li>Indikatoren als direkte Qualitätsurteile verwenden.</li>
          <li>Unterschiedliche Fächer oder Zeitfenster ohne Normalisierung vergleichen.</li>
          <li>Datenlücken oder Dubletten ignorieren.</li>
        </ul>

        <h3>Übungen</h3>
        <details>
          <summary>Level 1–3</summary>
          <div class="details-content">
            <h4>Level 1</h4>
            <ul>
              <li>Ein zentrales Konzept in zwei Sätzen definieren.</li>
            </ul>

            <h4>Level 2</h4>
            <ul>
              <li>Ein kleines Datenset skizzieren und passende Indikatoren vorschlagen.</li>
            </ul>

            <h4>Level 3</h4>
            <ul>
              <li>Eine kurze Interpretation schreiben und mögliche Bias benennen.</li>
            </ul>
          </div>
        </details>

        <h3>Quellen</h3>
        <ul>
          <li><a href="https://www.dora.org/">https://www.dora.org/</a></li>
          <li><a href="https://www.leidenmanifesto.org/">https://www.leidenmanifesto.org/</a></li>
          <li><a href="https://www.crossref.org/">https://www.crossref.org/</a></li>
        </ul>
      </section>

      <section class="module-section" id="modul-2" aria-labelledby="heading-modul-2">
        <h2 id="heading-modul-2">Modul 2: Publikationsdaten und Quellen</h2>
        <ul class="module-meta">
          <li><strong>Schwierigkeit:</strong> Beginner</li>
          <li><strong>Geschätzte Lesezeit:</strong> 50 Minuten</li>
          <li><strong>Zielgruppen:</strong> Bibliothek, Research Office, Forschende</li>
          <li><strong>Voraussetzungen:</strong> Modul 1</li>
        </ul>
        <div class="module-role-panel">
          <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
          <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
            <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
            <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
            <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
          </div>
          <div class="module-role-hints">
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Baut ein internes Standardblatt: „Welche Datenquelle für welche Frage?“
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Dokumentiert Coverage-Hinweise sichtbar im Report (z. B. als Methodik-Kasten).
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Vermeidet Tool-Mix ohne Erklärung: Wenn mehrere Quellen kombiniert werden, müsst ihr
              Dubletten/IDs klären.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Definiert früh den Zweck: Monitoring ≠ Bewertung. Die Datenquelle hängt am Ziel.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Für Governance: verlangt Standardangaben (Quelle, Zeitraum, Dokumenttypen, Limitationen).
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Wenn Ranking-Druck entsteht: nutzt Responsible-Metrics-Checks (Kontext + Multi-Indikator +
              qualitative Evidenz).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Wenn Zahlen nicht passen: prüfe zuerst Namensvarianten, Affiliations, Dokumenttypen und
              Zeitraum.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Nutze Kennzahlen in CVs nur mit kurzer Kontextzeile (Quelle + Zeitraum + Feld).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Für Themen-/Kooperationsanalysen können offene Quellen sehr nützlich sein – aber Ergebnisse
              immer plausibilisieren.
            </div>
          </div>
        </div>

        <h3>Lernziele</h3>
        <ul>
          <li>Die wichtigsten bibliometrischen Datenquellen unterscheiden.</li>
          <li>Verstehen, was „Coverage“ praktisch bedeutet.</li>
          <li>Erklären, warum Zahlen je nach Datenquelle unterschiedlich ausfallen können.</li>
          <li>Eine passende Datenquelle für eine konkrete Fragestellung auswählen und Limitationen kommunizieren.</li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Bibliometrische Kennzahlen sind nur so gut wie ihre Datenbasis. Unterschiedliche Datenquellen erfassen
          unterschiedliche Publikationen, Sprachen und Dokumenttypen – und verknüpfen Zitationen nicht immer gleich.
          Deshalb können zwei seriöse Systeme für dieselbe Einheit verschiedene Publikations- und Zitierzahlen zeigen.
          In diesem Modul lernst du, welche Quellen es gibt, wie Coverage entsteht und wie du Ergebnisse transparent und
          verantwortungsvoll kommunizierst.
        </p>

        <h3>Vertiefung</h3>
        <h4>Schlüsselbegriffe</h4>
        <ul>
          <li>
            <strong>Datenquelle:</strong> Ein System/Index, aus dem bibliometrische Daten stammen (z. B. kuratierte
            Zitationsdatenbank oder offene Metadateninfrastruktur).
          </li>
          <li>
            <strong>Coverage (Abdeckung):</strong> Welche Inhalte eine Datenquelle enthält (Zeitschriften,
            Konferenzen, Bücher, Sprachen, Länder, Jahre, Dokumenttypen).
          </li>
          <li>
            <strong>Indexierung:</strong> Wie Inhalte aufgenommen, strukturiert und verknüpft werden (z. B.
            Zitationslinks, Autor:innen, Institutionen).
          </li>
          <li>
            <strong>Kuratiert:</strong> Inhalte werden nach definierten Kriterien ausgewählt und redaktionell betreut.
          </li>
          <li>
            <strong>Offene Infrastruktur:</strong> Offene Daten/Metadaten (z. B. via API), die reproduzierbare Analysen
            ermöglichen, aber stark von Datenqualität abhängen.
          </li>
          <li>
            <strong>Bias:</strong> Systematische Verzerrung in Daten (z. B. Sprache, Region, Disziplin, Dokumenttyp),
            die Ergebnisse beeinflussen kann.
          </li>
        </ul>

        <h4>Die wichtigsten Datenquellen im Überblick</h4>
        <p>In der Bibliometrie gibt es grob drei Familien von Datenquellen:</p>
        <h5>1) Kuratierte Zitationsdatenbanken (z. B. WoS, Scopus)</h5>
        <ul>
          <li>Vorteil: definierte Selektions- und Indexierungslogik, konsistente Metadaten, stabile Auswertungen.</li>
          <li>Risiko: nicht jede Disziplin, Sprache oder Publikationsform ist gleich gut abgedeckt.</li>
        </ul>
        <h5>2) Offene Datenquellen (z. B. OpenAlex, Crossref)</h5>
        <ul>
          <li>Vorteil: offen zugänglich, API-basiert, reproduzierbar.</li>
          <li>Risiko: Metadatenqualität ist heterogen; Coverage kann je nach Bereich schwanken.</li>
        </ul>
        <h5>3) Suchmaschinen/Plattformen (z. B. Google Scholar)</h5>
        <ul>
          <li>Vorteil: häufig sehr breite Abdeckung.</li>
          <li>Risiko: begrenzte Transparenz, schwierig für belastbare Evaluation.</li>
        </ul>

        <h4>Warum unterscheiden sich Zahlen je nach Quelle?</h4>
        <ul>
          <li>Unterschiedliche Coverage (welche Journals/Konferenzen/Bücher enthalten sind)</li>
          <li>Unterschiedliche Dokumenttypen (z. B. Proceedings, Preprints)</li>
          <li>Unterschiedliche Indexierung (Zitationsverknüpfungen, Duplikate, Normalisierung)</li>
        </ul>

        <p><strong>Merksatz:</strong> Eine Kennzahl ohne Angabe der Datenquelle ist unvollständig.</p>

        <h4>Mini-Checkliste für jeden Report</h4>
        <ul>
          <li>Datenquelle(n): …</li>
          <li>Zeitraum: …</li>
          <li>Dokumenttypen: …</li>
          <li>Limitationen/Coverage-Hinweise: …</li>
          <li>Reproduzierbarkeit: Query/Datum dokumentiert: Ja/Nein</li>
        </ul>

        <h3>Typische Fehlinterpretationen</h3>
        <ul>
          <li>
            <strong>Mythos:</strong> „Wenn zwei Quellen unterschiedliche Zahlen liefern, ist eine falsch.“
            <strong>Korrektur:</strong> Unterschiede entstehen oft durch Coverage, Dokumenttypen und
            Indexierungslogik.
          </li>
          <li>
            <strong>Mythos:</strong> „Mehr Coverage bedeutet automatisch bessere Bibliometrie.“
            <strong>Korrektur:</strong> Transparenz, Datenqualität und definierte Regeln sind entscheidend.
          </li>
          <li>
            <strong>Mythos:</strong> „Wir können jede Disziplin gleich vergleichen.“
            <strong>Korrektur:</strong> Coverage und Zitationskulturen unterscheiden sich stark.
          </li>
          <li>
            <strong>Mythos:</strong> „Tools liefern neutrale Wahrheit.“
            <strong>Korrektur:</strong> Tools spiegeln Entscheidungen über Indexierung und Metadatenqualität wider.
          </li>
        </ul>

        <h4>Praxis-Workflow: Datenquelle auswählen</h4>
        <ol>
          <li>Frage klären: Monitoring, Reporting, Trendanalyse oder Evaluation?</li>
          <li>Analyseobjekt definieren: Person/Institut/Thema + Zeitraum + Publikationstypen.</li>
          <li>Kandidaten-Datenquellen auswählen (kuratierte DB vs. offen vs. Suchmaschine).</li>
          <li>Coverage prüfen: Disziplin, Sprache, Bücher/Proceedings, regionale Literatur.</li>
          <li>Testabfrage durchführen und plausibilisieren (Stichprobe gegen bekannte Publikationen).</li>
          <li>Bereinigung planen: IDs, Dubletten, Affiliations, Namensvarianten.</li>
          <li>Ergebnisbericht: immer mit Datenbasis + Limitationen + Datum der Abfrage.</li>
        </ol>

        <h4>Responsible-Metrics-Box: Minimum-Transparenz für Datenquellen</h4>
        <ul>
          <li>Nenne immer Datenquelle(n), Zeitraum und Dokumenttypen.</li>
          <li>
            Wenn Zahlen verglichen werden: erkläre Coverage-Unterschiede und warum der Vergleich sinnvoll ist (oder
            nicht).
          </li>
          <li>Vermeide mechanische Entscheidungen anhand einer einzigen Quelle oder Kennzahl.</li>
          <li>Nutze Bibliometrie als Hinweis-System: Ergebnisse sollten plausibilisiert und kontextualisiert werden.</li>
        </ul>

        <h3>Übungen</h3>
        <details>
          <summary>Level 1–3</summary>
          <div class="details-content">
            <h4>Level 1</h4>
            <ol>
              <li>
                <strong>M02-L1-Q1:</strong> Was bedeutet „Coverage“ in einer bibliometrischen Datenquelle?
                <ul>
                  <li>Wie viele Personen an einem Institut arbeiten.</li>
                  <li>Welche Publikationsarten, Disziplinen, Sprachen und Jahre in der Quelle enthalten sind.</li>
                  <li>Wie hoch der Journal Impact Factor ist.</li>
                </ul>
                <p><strong>Lösung:</strong> Welche Publikationsarten, Disziplinen, Sprachen und Jahre in der Quelle enthalten sind.</p>
              </li>
              <li>
                <strong>M02-L1-Q2:</strong> Welche Aussage ist am besten im Sinne von Responsible Metrics?
                <ul>
                  <li>Ein Report braucht keine Methodik, Hauptsache die Zahl ist klar.</li>
                  <li>Zu jeder Kennzahl gehören Datenquelle, Zeitraum und Limitationen.</li>
                  <li>Wenn zwei Tools verschieden zählen, nimmt man einfach den höheren Wert.</li>
                </ul>
                <p><strong>Lösung:</strong> Zu jeder Kennzahl gehören Datenquelle, Zeitraum und Limitationen.</p>
              </li>
              <li>
                <strong>M02-L1-Q3:</strong> Wähle die defensibelste Erklärung: Warum zeigt Quelle A mehr Publikationen als Quelle B?
                <ul>
                  <li>Quelle A hat wahrscheinlich mehr Dokumenttypen oder breitere Abdeckung indexiert.</li>
                  <li>Quelle B ist automatisch falsch.</li>
                  <li>Das Institut hat heimlich Publikationen gelöscht.</li>
                </ul>
                <p><strong>Lösung:</strong> Quelle A hat wahrscheinlich mehr Dokumenttypen oder breitere Abdeckung indexiert.</p>
              </li>
              <li>
                <strong>M02-L1-Q4:</strong> Was ist ein sinnvoller erster Schritt, bevor du zwei Datenquellen vergleichst?
                <ul>
                  <li>Sofort ein Ranking erstellen.</li>
                  <li>Dokumenttypen und Zeitraum angleichen und Coverage prüfen.</li>
                  <li>Nur nach Gefühl entscheiden, welche Quelle besser ist.</li>
                </ul>
                <p><strong>Lösung:</strong> Dokumenttypen und Zeitraum angleichen und Coverage prüfen.</p>
              </li>
              <li>
                <strong>M02-L1-Q5:</strong> Warum ist die Datenquelle in jedem Bibliometrie-Report Pflichtangabe?
                <ul>
                  <li>Weil Zahlen nur im Kontext der Coverage interpretierbar sind.</li>
                  <li>Weil sonst das Layout zu leer ist.</li>
                  <li>Weil Kennzahlen überall identisch sind.</li>
                </ul>
                <p><strong>Lösung:</strong> Weil Zahlen nur im Kontext der Coverage interpretierbar sind.</p>
              </li>
            </ol>

            <h4>Level 2</h4>
            <ol>
              <li>
                <strong>M02-L2-Q1:</strong> Interpretation: Zwei Quellen liefern unterschiedliche Publikationszahlen. Was schreibst du in den
                Report (2–3 Sätze, defensiv formuliert)?
                <table>
                  <thead>
                    <tr>
                      <th>Einheit</th>
                      <th>Zeitraum</th>
                      <th>Quelle</th>
                      <th>Publikationen</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Institut A</td>
                      <td>2021–2024</td>
                      <td>Quelle 1</td>
                      <td>120</td>
                    </tr>
                    <tr>
                      <td>Institut A</td>
                      <td>2021–2024</td>
                      <td>Quelle 2</td>
                      <td>155</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  <strong>Lösung:</strong> Die unterschiedlichen Werte sind wahrscheinlich durch abweichende Coverage erklärbar. Für die
                  Interpretation ist entscheidend, welche Datenquelle zur Fragestellung passt. Im Report werden
                  Datenquelle, Zeitraum, Dokumenttypen und Limitationen transparent dokumentiert.
                </p>
              </li>
              <li>
                <strong>M02-L2-Q2:</strong> Quelle auswählen: Du brauchst ein reproduzierbares Monitoring-Dashboard ohne Paywall. Welche
                Datenquelle passt am ehesten und welche Einschränkung nennst du?
                <p>
                  <strong>Lösung:</strong> OpenAlex (API-basiert, offen, reproduzierbar) ist naheliegend. Einschränkung: Coverage und
                  Metadatenqualität können variieren; deshalb braucht es Plausibilisierung und Dokumentation der
                  Abfrageparameter.
                </p>
              </li>
              <li>
                <strong>M02-L2-Q3:</strong> Quality Check: Nenne 3 Prüfungen, die du bei einer Publikationsliste aus einer Datenquelle machst,
                bevor du Kennzahlen berichtest.
                <p>
                  <strong>Lösung:</strong> Beispiele: Dublettenprüfung, Namensvarianten/IDs plausibilisieren, Affiliations prüfen,
                  Dokumenttypen filtern, Zeitraum korrekt setzen.
                </p>
              </li>
            </ol>

            <h4>Level 3</h4>
            <ol>
              <li>
                <strong>M02-L3-CASE:</strong> Mini-Case: Du sollst für eine Fakultät einen Vergleich „Publikationsoutput 2020–2024“ erstellen.
                Definiere deine Datenbasis (Quelle(n), Dokumenttypen, Zeitraum) und formuliere 4 Limitationen/Warnhinweise.
                <p><strong>Deliverable:</strong> Methodik-Kasten + 4 Limitationen (Bulletpoints).</p>
              </li>
            </ol>
          </div>
        </details>

        <h3>Quellen</h3>
        <ul>
          <li>
            Clarivate: Web of Science Core Collection – Content collection and indexing process:
            <a
              href="https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/web-of-science-core-collection/content-collection-and-indexing-process/"
              >https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/web-of-science-core-collection/content-collection-and-indexing-process/</a
            >
          </li>
          <li>
            Elsevier: Scopus Content Coverage Guide (PDF):
            <a
              href="https://assets.ctfassets.net/o78em1y1w4i4/EX1iy8VxBeQKf8aN2XzOp/c36f79db25484cb38a5972ad9a5472ec/Scopus_ContentCoverage_Guide_WEB.pdf"
              >https://assets.ctfassets.net/o78em1y1w4i4/EX1iy8VxBeQKf8aN2XzOp/c36f79db25484cb38a5972ad9a5472ec/Scopus_ContentCoverage_Guide_WEB.pdf</a
            >
          </li>
          <li>
            OpenAlex Documentation: API Overview:
            <a href="https://docs.openalex.org/how-to-use-the-api/api-overview"
              >https://docs.openalex.org/how-to-use-the-api/api-overview</a
            >
          </li>
          <li>
            Crossref Documentation: Metadata Retrieval:
            <a href="https://www.crossref.org/documentation/retrieve-metadata/"
              >https://www.crossref.org/documentation/retrieve-metadata/</a
            >
          </li>
          <li>
            CWTS (Leiden): Bibliometrics for Research Management (PDF):
            <a href="https://www.cwts.nl/pdf/CWTS_bibliometrics.pdf">https://www.cwts.nl/pdf/CWTS_bibliometrics.pdf</a>
          </li>
          <li>
            Gusenbauer &amp; Haddaway (2020): Suitable academic search systems (PubMed):
            <a href="https://pubmed.ncbi.nlm.nih.gov/31614060/">https://pubmed.ncbi.nlm.nih.gov/31614060/</a>
          </li>
          <li>
            Gusenbauer (2024): Beyond Google Scholar, Scopus, and WoS:
            <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1729"
              >https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1729</a
            >
          </li>
        </ul>

        <h4>Weiterführende Lektüre</h4>
        <ul>
          <li>
            López-Cózar (2018): Google Scholar as bibliographic tool (arXiv PDF):
            <a href="https://arxiv.org/pdf/1806.06351">https://arxiv.org/pdf/1806.06351</a>
          </li>
          <li>
            Dimensions Support: What is covered in Publications?:
            <a href="https://plus.dimensions.ai/support/solutions/articles/23000018859-what-exactly-is-covered-in-the-publications-in-dimensions-"
              >https://plus.dimensions.ai/support/solutions/articles/23000018859-what-exactly-is-covered-in-the-publications-in-dimensions-</a
            >
          </li>
        </ul>
      </section>

      <section class="module-section" id="modul-3" aria-labelledby="heading-modul-3">
        <h2 id="heading-modul-3">Modul 3: Zitationsindikatoren</h2>
        <ul class="module-meta">
          <li><strong>Schwierigkeit:</strong> Beginner</li>
          <li><strong>Geschätzte Lesezeit:</strong> 55 Minuten</li>
          <li><strong>Zielgruppen:</strong> Bibliothek, Forschungsreferat, Forschende</li>
          <li><strong>Voraussetzungen:</strong> Modul 1, Modul 2</li>
        </ul>
        <div class="module-role-panel">
          <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
          <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
            <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
            <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
            <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
          </div>
          <div class="module-role-hints">
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: In Beratungen zuerst Datenbasis prüfen, dann interpretieren.
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Zitationen immer mit Zitationsfenster und Abfragedatum ausweisen.
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Wenn möglich, Standardformulierung für Zitationszahlen nutzen.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Zitationszahlen als Trend- und Kontextsignal nutzen, nicht als Ranking.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Bestehe auf Mindest-Transparenz (Quelle, Fenster, Selbstzitate, Dokumenttypen).
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Bei Entscheidungen auf Multi-Methoden-Ansatz setzen (quantitativ + qualitativ).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Vergleiche nur innerhalb sinnvoller Gruppen (Fach, Karrierestufe, Publikationstyp, Alter).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Kontextzeile mit Quelle + Zeitraum + Fenster ergänzen.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Bei Peaks prüfen, ob Reviews/Methodenpapiere oder Datenartefakte vorliegen.
            </div>
          </div>
        </div>

        <h3>Lernziele</h3>
        <ul>
          <li>Zitationen als Signal (nicht als Beweis) verstehen.</li>
          <li>Zitationsfenster und Zeitdynamiken erklären.</li>
          <li>Selbstzitate und Zitationskontext korrekt einordnen.</li>
          <li>Zitationskennzahlen transparent berichten.</li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Eine Zitation ist ein Verweis von einer Publikation auf eine andere. Zitationszahlen werden oft genutzt, um
          Resonanz oder Sichtbarkeit zu beschreiben. Aber: Zitationen sind kein direkter Qualitätsbeweis. Sie hängen vom
          Fachgebiet, vom Alter eines Artikels, vom Publikationstyp und von der Datenquelle ab. Zusätzlich sind nicht alle
          Zitationen „Lob“ – manche sind neutral oder kritisch. Deshalb brauchst du beim Interpretieren immer Kontext:
          Zitationsfenster, Fachgebiet, Datenbasis und klare Limitationen.
        </p>

        <h3>Vertiefung</h3>
        <h4>Schlüsselbegriffe</h4>
        <ul>
          <li>
            <strong>Zitation (Citation):</strong> Verweis auf eine Publikation; Signal für Resonanz, nicht automatisch Qualität.
          </li>
          <li><strong>Zitationszählung:</strong> Anzahl Zitationen in einer Datenquelle innerhalb eines Zeitraums.</li>
          <li><strong>Zitationsfenster:</strong> Zeitraum, in dem Zitationen gezählt werden (z. B. 2, 4, 5 oder 10 Jahre).</li>
          <li><strong>Zitationsverzögerung:</strong> Zeit, bis eine Publikation zitiert wird.</li>
          <li><strong>Selbstzitation:</strong> Zitationen, bei denen sich Autor:innen selbst zitieren.</li>
          <li><strong>Zitationskontext:</strong> Verwendung der Zitation (zustimmend, neutral, kritisch).</li>
          <li><strong>Feldunterschiede:</strong> Unterschiede in Publikations- und Zitationskulturen.</li>
        </ul>

        <h4>Wie Zitationsdaten entstehen – und warum sie tückisch sein können</h4>
        <ol>
          <li>
            <strong>Zeitdynamik (Alter zählt):</strong> Neuere Publikationen hatten weniger Zeit, Zitationen zu sammeln. Darum ist
            das Zitationsfenster ein zentraler Parameter.
          </li>
          <li>
            <strong>Verteilung:</strong> Zitationen sind stark ungleich verteilt; Durchschnittswerte können irreführend sein.
          </li>
          <li>
            <strong>Dokumenttyp-Effekt:</strong> Reviews und Methodenpapiere werden oft häufiger zitiert als Spezialstudien.
          </li>
          <li>
            <strong>Selbstzitate:</strong> Legitimes Anschlusszitat, kann Kennzahlen verzerren. Gute Praxis: mit und ohne
            Selbstzitate ausweisen.
          </li>
          <li>
            <strong>Zitationskontext:</strong> Zitationen können zustimmend, neutral oder kritisch sein; nicht jede Zitation ist
            „positiv“.
          </li>
        </ol>

        <p>
          <strong>Praktische Konsequenz:</strong> Zitationszahlen immer mit Datenquelle, Abfragedatum, Zeitraum/Zitationsfenster,
          Dokumenttypen, Selbstzitate-Regel und Limitationen dokumentieren.
        </p>

        <h4>Praxis-Workflow: Zitationen korrekt berichten</h4>
        <ol>
          <li>Ziel klären: Monitoring, Kontext im CV, Report oder Evaluation?</li>
          <li>Datenquelle festlegen (und begründen) + Abfragedatum dokumentieren.</li>
          <li>Zitationsfenster definieren und konsistent halten.</li>
          <li>Dokumenttypen festlegen (z. B. Article/Review getrennt ausweisen).</li>
          <li>Selbstzitate-Regel definieren (mit/ohne) und transparent berichten.</li>
          <li>Ergebnisse plausibilisieren (Stichprobe, Ausreißer prüfen, Kontext beachten).</li>
          <li>Methodik-Kasten + Limitationen + Responsible-Metrics-Hinweisbox einfügen.</li>
        </ol>

        <h4>Responsible Metrics: Zitationen</h4>
        <ul>
          <li>Zitationen sind Kontextsignale, keine automatische Qualitätsnote.</li>
          <li>Zitationsfenster und Alter sind Pflichtkontext für jede Interpretation.</li>
          <li>Dokumenttypen und Fachgebiet berücksichtigen.</li>
          <li>Selbstzitate transparent behandeln.</li>
          <li>Bei Evaluationen: Zitationen nur zusammen mit qualitativen Verfahren nutzen.</li>
        </ul>

        <h3>Typische Fehlinterpretationen</h3>
        <ul>
          <li>
            <strong>„Viele Zitationen beweisen hohe Qualität.“</strong> Zitationen sind ein Signal, beeinflusst durch Feld, Alter,
            Dokumenttyp und Kontext.
          </li>
          <li>
            <strong>„Neuere Publikationen sind schwächer.“</strong> Oft ist das ein Zeitfenster-Effekt; Vergleiche brauchen
            passende Fenster.
          </li>
          <li>
            <strong>„Selbstzitate sind immer Betrug.“</strong> Häufig legitim, wichtig ist Transparenz.
          </li>
          <li>
            <strong>„Alle Zitationen sind positiv.“</strong> Zitationen können neutral oder kritisch sein.
          </li>
          <li>
            <strong>„Man kann jedes Fachgebiet direkt vergleichen.“</strong> Zitationskulturen unterscheiden sich stark.
          </li>
        </ul>

        <h3>Übungen</h3>
        <details>
          <summary>Level 1–3</summary>
          <div class="details-content">
            <h4>Level 1</h4>
            <ol>
              <li>
                <strong>M03-L1-Q1:</strong> Welche Aussage zu Zitationen ist am defensibelsten?
                <ul>
                  <li>Viele Zitationen beweisen, dass die Forschung qualitativ besser ist.</li>
                  <li>Zitationen können Sichtbarkeit anzeigen, müssen aber mit Kontext interpretiert werden.</li>
                  <li>Zitationen sind wertlos und sollten nie verwendet werden.</li>
                </ul>
                <p><strong>Lösung:</strong> Zitationen können Sichtbarkeit anzeigen, müssen aber mit Kontext interpretiert werden.</p>
              </li>
              <li>
                <strong>M03-L1-Q2:</strong> Was ist ein Zitationsfenster (Citation Window)?
                <ul>
                  <li>Die Anzahl Referenzen im Literaturverzeichnis.</li>
                  <li>Der Zeitraum, in dem Zitationen gezählt werden (z. B. 4 Jahre).</li>
                  <li>Die Anzahl Publikationen pro Jahr.</li>
                </ul>
                <p><strong>Lösung:</strong> Der Zeitraum, in dem Zitationen gezählt werden (z. B. 4 Jahre).</p>
              </li>
              <li>
                <strong>M03-L1-Q3:</strong> Welche Aussage zu Selbstzitaten passt am besten?
                <ul>
                  <li>Selbstzitate sind immer Betrug.</li>
                  <li>Selbstzitate können legitim sein, sollten aber je nach Zweck transparent behandelt werden.</li>
                  <li>Selbstzitate zählen nie in Datenquellen.</li>
                </ul>
                <p><strong>Lösung:</strong> Selbstzitate können legitim sein, sollten aber je nach Zweck transparent behandelt werden.</p>
              </li>
              <li>
                <strong>M03-L1-Q4:</strong> Welche Aussage ist korrekt?
                <ul>
                  <li>Alle Zitationen sind positive Anerkennung.</li>
                  <li>Zitationen können auch kritisch oder neutral sein.</li>
                  <li>Negative Zitationen sind unmöglich.</li>
                </ul>
                <p><strong>Lösung:</strong> Zitationen können auch kritisch oder neutral sein.</p>
              </li>
              <li>
                <strong>M03-L1-Q5:</strong> Warum sind Vergleiche zwischen Fachgebieten schwierig?
                <ul>
                  <li>Weil Zitations- und Publikationskulturen je nach Fach unterschiedlich sind.</li>
                  <li>Weil alle Fächer identisch publizieren.</li>
                  <li>Weil Datenquellen immer vollständig sind.</li>
                </ul>
                <p><strong>Lösung:</strong> Weil Zitations- und Publikationskulturen je nach Fach unterschiedlich sind.</p>
              </li>
            </ol>

            <h4>Level 2</h4>
            <ol>
              <li>
                <strong>M03-L2-Q1:</strong> Zitationsfenster-Effekt: Welche Interpretation ist korrekt?
                <table>
                  <thead>
                    <tr>
                      <th>Paper</th>
                      <th>Year</th>
                      <th>Citations in 2024 (cum.)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>A</td>
                      <td>2019</td>
                      <td>45</td>
                    </tr>
                    <tr>
                      <td>B</td>
                      <td>2023</td>
                      <td>8</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  <strong>Lösung:</strong> Paper A hatte mehr Zeit, Zitationen zu sammeln. Ein direkter Vergleich ohne gleiches
                  Zitationsfenster oder Altersklassen ist unfair. Für einen faireren Vergleich sollte man Zitationen
                  innerhalb eines definierten Fensters betrachten.
                </p>
              </li>
              <li>
                <strong>M03-L2-Q2:</strong> Selbstzitate: Formuliere eine Report-Zeile (1–2 Sätze), die Zitationen mit und ohne Selbstzitate
                transparent ausweist.
                <table>
                  <thead>
                    <tr>
                      <th>Einheit</th>
                      <th>Zeitraum</th>
                      <th>Zitationen (gesamt)</th>
                      <th>Zitationen (ohne Selbstzitate)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Institut A</td>
                      <td>2020–2024</td>
                      <td>980</td>
                      <td>840</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  <strong>Lösung:</strong> Im Zeitraum 2020–2024 wurden 980 Zitationen gezählt; ohne Selbstzitate sind es 840. Die Differenz
                  wird zur Transparenz separat ausgewiesen.
                </p>
              </li>
              <li>
                <strong>M03-L2-Q3:</strong> Dokumenttyp-Effekt: Warum kann ein Review-Artikel Zitationszahlen verzerren? Nenne 2 Gründe.
                <p>
                  <strong>Lösung:</strong> Reviews bündeln Literatur und werden oft als Einstieg zitiert. Außerdem werden Methoden- und
                  Übersichtsarbeiten quer über Teilfelder zitiert, was Vergleiche verzerren kann.
                </p>
              </li>
            </ol>

            <h4>Level 3</h4>
            <ol>
              <li>
                <strong>M03-L3-CASE:</strong> Mini-Case: Formuliere einen Methodik-Kasten (Quelle, Abfragedatum, Zitationsfenster,
                Dokumenttypen, Umgang mit Selbstzitaten) und 4 Limitationen/Warnhinweise zur Interpretation.
              </li>
            </ol>
          </div>
        </details>

        <h3>Quellen</h3>
        <ul>
          <li>
            Garfield, E. (1955). Citation Indexes for Science. Science (PDF).
            <a href="https://garfield.library.upenn.edu/papers/science1955.pdf"
              >https://garfield.library.upenn.edu/papers/science1955.pdf</a
            >
          </li>
          <li>
            Hicks, D. et al. (2015). The Leiden Manifesto for research metrics. Nature.
            <a href="https://www.nature.com/articles/520429a">https://www.nature.com/articles/520429a</a>
          </li>
          <li>
            DORA (2012). San Francisco Declaration on Research Assessment.
            <a href="https://sfdora.org/read/">https://sfdora.org/read/</a>
          </li>
          <li>
            Wilsdon, J. et al. (2015). The Metric Tide (PDF).
            <a href="https://www.ukri.org/wp-content/uploads/2021/12/RE-151221-TheMetricTideFullReport2015.pdf"
              >https://www.ukri.org/wp-content/uploads/2021/12/RE-151221-TheMetricTideFullReport2015.pdf</a
            >
          </li>
          <li>
            Waltman, L. (2016). A review of the literature on citation impact indicators. Journal of Informetrics.
            <a href="https://www.sciencedirect.com/science/article/pii/S1751157715300900"
              >https://www.sciencedirect.com/science/article/pii/S1751157715300900</a
            >
          </li>
          <li>
            Fowler, J. H., &amp; Aksnes, D. W. (2007). Does self-citation pay? Scientometrics.
            <a href="https://link.springer.com/article/10.1007/s11192-007-1777-2"
              >https://link.springer.com/article/10.1007/s11192-007-1777-2</a
            >
          </li>
          <li>
            Moed, H. F. (2007). Developing Bibliometric Indicators of Research Performance (CWTS report, PDF).
            <a href="https://www.cwts.nl/pdf/nwo_inf_final_report_v_210207.pdf"
              >https://www.cwts.nl/pdf/nwo_inf_final_report_v_210207.pdf</a
            >
          </li>
          <li>
            Xu, J. et al. (2015). Citation Sentiment Analysis in Clinical Trial Papers (PMC).
            <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC4765697/">https://pmc.ncbi.nlm.nih.gov/articles/PMC4765697/</a>
          </li>
          <li>
            Song, D. et al. (2022). Quantifying characteristics of negative citations. Information Processing &amp; Management.
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457322001108"
              >https://www.sciencedirect.com/science/article/abs/pii/S0306457322001108</a
            >
          </li>
        </ul>

        <h4>Weiterführende Lektüre</h4>
        <ul>
          <li>
            Waltman (Preprint). A review of the literature on citation impact indicators (arXiv).
            <a href="https://arxiv.org/abs/1507.02099">https://arxiv.org/abs/1507.02099</a>
          </li>
        </ul>
      </section>

      <section class="module-section" id="modul-4" aria-labelledby="heading-modul-4">
        <h2 id="heading-modul-4">Modul 4: Metriken für Autor:innen</h2>
        <ul class="module-meta">
          <li><strong>Schwierigkeit:</strong> 2</li>
          <li><strong>Geschätzte Lesezeit:</strong> 25 Minuten</li>
          <li><strong>Zielgruppen:</strong> Bibliothek, Forschungsreferat, Forschende</li>
          <li><strong>Voraussetzungen:</strong> Modul 1, Modul 2, Modul 3</li>
        </ul>
        <div class="module-role-panel">
          <p class="module-role-label">Wähle deine Rolle für passende Hinweise:</p>
          <div class="module-role-buttons" role="group" aria-label="Rolle auswählen">
            <button type="button" class="role-toggle-button" data-role="Bibliothek">Bibliothek</button>
            <button type="button" class="role-toggle-button" data-role="Research Office">Research Office</button>
            <button type="button" class="role-toggle-button" data-role="Forschende">Forschende</button>
          </div>
          <div class="module-role-hints">
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Prüft Autor:innenprofile aktiv auf Dubletten, bevor ihr Kennzahlen angebt.
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Legt eine Standardformulierung für Quelle, Stichtag und Regeln fest.
            </div>
            <div class="role-hint" data-role="Bibliothek" hidden>
              Hinweis: Vermittelt Unterschiede zwischen h-, g- und i10-Index mit Beispielrechnungen.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Nutzt Autor:innenmetriken nur im Kontext von Karrierestufe und Fach.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Bestehe auf Transparenz zu Datenquelle und Selbstzitate-Regel.
            </div>
            <div class="role-hint" data-role="Research Office" hidden>
              Hinweis: Kombiniert Kennzahlen mit qualitativen Einschätzungen in Reports.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Vergleiche nur in sinnvollen Gruppen (Fach, Karrierestufe, Dokumenttypen).
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Ergänze jede Kennzahl um Quelle, Stichtag und Limitationen.
            </div>
            <div class="role-hint" data-role="Forschende" hidden>
              Hinweis: Prüfe die eigene Publikationsliste auf fehlende oder falsche Zuordnungen.
            </div>
          </div>
        </div>

        <h3>Lernziele</h3>
        <ul>
          <li>Die Logik von h-Index, g-Index, i10-Index und m-Quotient erklären (inkl. was sie NICHT messen).</li>
          <li>Einfache Metriken aus einer Zitationsliste korrekt berechnen.</li>
          <li>Typische Verzerrungen erkennen (Karrierelänge, Dokumenttyp, Datenquelle, Autor:innen-Identität, Selbstzitate).</li>
          <li>Metriken report-tauglich kommunizieren (Quelle, Stichtag, Zeitraum/Fenster, Regeln, Limitationen).</li>
        </ul>

        <h3>Kurz erklärt</h3>
        <p>
          Autor:innenmetriken (h, g, i10, m) liefern ein kompaktes Signal für Publikations- und Zitationsmuster. Sie sind
          hilfreich für Überblick und Monitoring – aber riskant als alleinige Bewertungsgrundlage. Die Werte hängen stark
          von Datenquelle, Karrierelänge, Dokumenttyp (z. B. Reviews) und sauberer Autor:innen-Zuordnung ab. Gute Praxis:
          nie nur eine Kennzahl, sondern immer Kontext, Regeln und Limitationen mitliefern.
        </p>

        <h3>Vertiefung</h3>
        <h4>Schlüsselbegriffe</h4>
        <ul>
          <li>
            <strong>h-Index:</strong> h = Anzahl Publikationen, die jeweils mindestens h Zitationen haben (bei absteigend
            sortierter Zitationsliste).
          </li>
          <li>
            <strong>g-Index:</strong> g = größte Zahl, sodass die Top-g Publikationen zusammen mindestens g² Zitationen haben.
          </li>
          <li>
            <strong>i10-Index:</strong> Anzahl Publikationen mit mindestens 10 Zitationen (vor allem in Google Scholar genutzt).
          </li>
          <li>
            <strong>m-Quotient (m-Index):</strong> Karrierezeit-Korrektur: häufig h geteilt durch Anzahl Jahre seit der ersten
            Publikation.
          </li>
          <li>
            <strong>Autor:innen-Disambiguierung:</strong> Saubere Zuordnung von Publikationen zu einer Person (Namensvarianten,
            Affiliations, Doppelprofile).
          </li>
          <li>
            <strong>Datenquelle:</strong> Woher die Zitations-/Publikationsdaten stammen (z. B. WoS, Scopus, Google Scholar,
            OpenAlex).
          </li>
        </ul>

        <h4>Die 4 wichtigsten Metriken (mit Interpretation)</h4>

        <h5>h-Index</h5>
        <ul>
          <li><strong>Was er abbildet:</strong> Breite, anhaltende Resonanz (nicht nur ein einzelner „Hit“).</li>
          <li><strong>Berechnung:</strong> Sortiere Zitationen absteigend. Finde die größte Position h: Zitationen(h) ≥ h.</li>
          <li>
            <strong>Stärken:</strong> Robust gegen einzelne extreme Ausreißer; einfach erklärbar.
          </li>
          <li>
            <strong>Grenzen:</strong> Bevorzugt längere Karrieren; unfair zwischen Feldern; ignoriert Kontext; abhängig von
            Abdeckung.
          </li>
        </ul>

        <h5>g-Index</h5>
        <ul>
          <li><strong>Was er abbildet:</strong> Gewichtet sehr stark zitierte Arbeiten stärker als der h-Index.</li>
          <li>
            <strong>Berechnung:</strong> Sortiere absteigend. g ist die größte Zahl mit: Summe(top g) ≥ g².
          </li>
          <li><strong>Stärken:</strong> Reagiert auf „Big Hits“; unterscheidet Profile mit gleichen h-Werten besser.</li>
          <li><strong>Grenzen:</strong> Abdeckungssensitiv; kann von wenigen sehr stark zitierten Arbeiten dominiert werden.</li>
        </ul>

        <h5>i10-Index</h5>
        <ul>
          <li><strong>Was er abbildet:</strong> Einfache Schwelle: ≥ 10 Zitationen.</li>
          <li><strong>Berechnung:</strong> Zähle Publikationen mit mindestens 10 Zitationen.</li>
          <li><strong>Stärken:</strong> Sehr leicht zu erklären; schneller Überblick.</li>
          <li><strong>Grenzen:</strong> Grob und feldabhängig; stark datenquellenabhängig; nicht überall etabliert.</li>
        </ul>

        <h5>m-Quotient (m-Index)</h5>
        <ul>
          <li><strong>Was er abbildet:</strong> Grobe Karrierezeit-Korrektur (h pro Jahr).</li>
          <li><strong>Berechnung:</strong> m = h / (Jahre seit erster Publikation).</li>
          <li><strong>Stärken:</strong> Hilft beim Vergleich unterschiedlicher Seniorität (grobe Näherung).</li>
          <li><strong>Grenzen:</strong> Sehr grob; Feld-/Dokumenttyp-Effekte bleiben; Jahresdefinition muss fixiert werden.</li>
        </ul>

        <h3>Typische Fallen &amp; Fehlinterpretationen</h3>
        <ul>
          <li>
            <strong>„Eine Zahl reicht, um Leistung zu bewerten.“</strong> Metriken sind Kontextsignale – niemals allein.
          </li>
          <li>
            <strong>„h-Index aus Quelle A = h-Index aus Quelle B.“</strong> Coverage und Verknüpfung unterscheiden sich stark.
          </li>
          <li>
            <strong>„Ein niedriger h bedeutet schlechte Forschung.“</strong> Karrierelänge, Feld und Datenbasis beeinflussen
            den Wert.
          </li>
          <li>
            <strong>„Autor:innenprofile stimmen schon.“</strong> Namensvarianten und Doppelprofile sind häufig.
          </li>
        </ul>

        <h3>Praxis-Workflow: Autor:innenmetriken sauber erheben</h3>
        <ol>
          <li>Zweck klären: Monitoring, CV-Kontext, Bericht oder Evaluation?</li>
          <li>Datenquelle(n) festlegen und dokumentieren (inkl. Stichtag der Abfrage).</li>
          <li>Autor:innenprofil bereinigen (Namensvarianten, Dubletten, falsche Zuordnung).</li>
          <li>Regeln definieren: Zeitraum/Zitationsfenster? Dokumenttypen? Umgang mit Selbstzitaten?</li>
          <li>Metriken berechnen (h, g, i10, optional m).</li>
          <li>Plausibilisieren: Ausreißer prüfen, Stichprobe gegen bekannte Publikationen.</li>
          <li>Report schreiben: Methodik-Kasten + Limitationen + verantwortungsvolle Interpretation.</li>
        </ol>

        <h3>Responsible Metrics: Mindeststandard für Autor:innenmetriken</h3>
        <ul>
          <li>Nie eine Kennzahl alleine verwenden; immer Kontext + mehrere Signale.</li>
          <li>Immer angeben: Datenquelle, Stichtag, Zeitraum/Fenster, Dokumenttypen, Regeln (z. B. Selbstzitate ja/nein).</li>
          <li>Vergleiche nur in sinnvollen Gruppen (Fach, Karrierestufe, Dokumenttypen).</li>
          <li>Bei Entscheidungen: quantitative Indikatoren nur zusammen mit qualitativer Begutachtung nutzen.</li>
        </ul>

        <h3>Übungen</h3>
        <details>
          <summary>Level 1</summary>
          <div class="details-content">
            <ol>
              <li>
                <strong>M04-L1-Q1:</strong> Welche Definition trifft den h-Index am besten?
                <ul>
                  <li>Anzahl Publikationen insgesamt.</li>
                  <li>h Publikationen haben jeweils mindestens h Zitationen.</li>
                  <li>Durchschnittliche Zitationen pro Publikation.</li>
                </ul>
                <p><strong>Lösung:</strong> h Publikationen haben jeweils mindestens h Zitationen.</p>
              </li>
              <li>
                <strong>M04-L1-Q2:</strong> Was misst der i10-Index?
                <ul>
                  <li>Durchschnittliche Zitationen pro Jahr.</li>
                  <li>Anzahl Publikationen mit mindestens 10 Zitationen.</li>
                  <li>Anzahl Zitationen im letzten Jahr.</li>
                </ul>
                <p><strong>Lösung:</strong> Anzahl Publikationen mit mindestens 10 Zitationen.</p>
              </li>
              <li>
                <strong>M04-L1-Q3:</strong> Welche Aussage ist verantwortungsvoll?
                <ul>
                  <li>Wir ranken Forschende nur nach h-Index.</li>
                  <li>Wir nennen Quelle, Stichtag und Regeln und interpretieren im Kontext.</li>
                  <li>Wenn zwei Datenbanken abweichen, nehmen wir den höheren Wert.</li>
                </ul>
                <p><strong>Lösung:</strong> Wir nennen Quelle, Stichtag und Regeln und interpretieren im Kontext.</p>
              </li>
            </ol>
          </div>
        </details>
      </section>
    </main>
    <script src="role-toggle.js" defer></script>
  </body>
</html>
